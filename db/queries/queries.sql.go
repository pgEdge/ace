// Code generated by pggen. DO NOT EDIT.

package queries

import (
	"context"
	"fmt"
	"github.com/jackc/pgconn"
	"github.com/jackc/pgtype"
	"github.com/jackc/pgx/v4"
)

// Querier is a typesafe Go interface backed by SQL queries.
//
// Methods ending with Batch enqueue a query to run later in a pgx.Batch. After
// calling SendBatch on pgx.Conn, pgxpool.Pool, or pgx.Tx, use the Scan methods
// to parse the results.
type Querier interface {
	EstimateRowCount(ctx context.Context, schemaName pgtype.Name, tableName pgtype.Name) (*int, error)
	// EstimateRowCountBatch enqueues a EstimateRowCount query into batch to be executed
	// later by the batch.
	EstimateRowCountBatch(batch genericBatch, schemaName pgtype.Name, tableName pgtype.Name)
	// EstimateRowCountScan scans the result of an executed EstimateRowCountBatch query.
	EstimateRowCountScan(results pgx.BatchResults) (*int, error)

	GetPrimaryKey(ctx context.Context, schemaName pgtype.Name, tableName pgtype.Name) ([]pgtype.Name, error)
	// GetPrimaryKeyBatch enqueues a GetPrimaryKey query into batch to be executed
	// later by the batch.
	GetPrimaryKeyBatch(batch genericBatch, schemaName pgtype.Name, tableName pgtype.Name)
	// GetPrimaryKeyScan scans the result of an executed GetPrimaryKeyBatch query.
	GetPrimaryKeyScan(results pgx.BatchResults) ([]pgtype.Name, error)

	GetColumnTypes(ctx context.Context, tableName pgtype.Name) ([]GetColumnTypesRow, error)
	// GetColumnTypesBatch enqueues a GetColumnTypes query into batch to be executed
	// later by the batch.
	GetColumnTypesBatch(batch genericBatch, tableName pgtype.Name)
	// GetColumnTypesScan scans the result of an executed GetColumnTypesBatch query.
	GetColumnTypesScan(results pgx.BatchResults) ([]GetColumnTypesRow, error)

	GetColumns(ctx context.Context, schemaName pgtype.Name, tableName pgtype.Name) ([]pgtype.Name, error)
	// GetColumnsBatch enqueues a GetColumns query into batch to be executed
	// later by the batch.
	GetColumnsBatch(batch genericBatch, schemaName pgtype.Name, tableName pgtype.Name)
	// GetColumnsScan scans the result of an executed GetColumnsBatch query.
	GetColumnsScan(results pgx.BatchResults) ([]pgtype.Name, error)

	CheckUserPrivileges(ctx context.Context, params CheckUserPrivilegesParams) (CheckUserPrivilegesRow, error)
	// CheckUserPrivilegesBatch enqueues a CheckUserPrivileges query into batch to be executed
	// later by the batch.
	CheckUserPrivilegesBatch(batch genericBatch, params CheckUserPrivilegesParams)
	// CheckUserPrivilegesScan scans the result of an executed CheckUserPrivilegesBatch query.
	CheckUserPrivilegesScan(results pgx.BatchResults) (CheckUserPrivilegesRow, error)

	SpockNodeAndSubInfo(ctx context.Context) ([]SpockNodeAndSubInfoRow, error)
	// SpockNodeAndSubInfoBatch enqueues a SpockNodeAndSubInfo query into batch to be executed
	// later by the batch.
	SpockNodeAndSubInfoBatch(batch genericBatch)
	// SpockNodeAndSubInfoScan scans the result of an executed SpockNodeAndSubInfoBatch query.
	SpockNodeAndSubInfoScan(results pgx.BatchResults) ([]SpockNodeAndSubInfoRow, error)

	SpockRepSetInfo(ctx context.Context) ([]SpockRepSetInfoRow, error)
	// SpockRepSetInfoBatch enqueues a SpockRepSetInfo query into batch to be executed
	// later by the batch.
	SpockRepSetInfoBatch(batch genericBatch)
	// SpockRepSetInfoScan scans the result of an executed SpockRepSetInfoBatch query.
	SpockRepSetInfoScan(results pgx.BatchResults) ([]SpockRepSetInfoRow, error)
}

type DBQuerier struct {
	conn  genericConn   // underlying Postgres transport to use
	types *typeResolver // resolve types by name
}

var _ Querier = &DBQuerier{}

// genericConn is a connection to a Postgres database. This is usually backed by
// *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
type genericConn interface {
	// Query executes sql with args. If there is an error the returned Rows will
	// be returned in an error state. So it is allowed to ignore the error
	// returned from Query and handle it in Rows.
	Query(ctx context.Context, sql string, args ...interface{}) (pgx.Rows, error)

	// QueryRow is a convenience wrapper over Query. Any error that occurs while
	// querying is deferred until calling Scan on the returned Row. That Row will
	// error with pgx.ErrNoRows if no rows are returned.
	QueryRow(ctx context.Context, sql string, args ...interface{}) pgx.Row

	// Exec executes sql. sql can be either a prepared statement name or an SQL
	// string. arguments should be referenced positionally from the sql string
	// as $1, $2, etc.
	Exec(ctx context.Context, sql string, arguments ...interface{}) (pgconn.CommandTag, error)
}

// genericBatch batches queries to send in a single network request to a
// Postgres server. This is usually backed by *pgx.Batch.
type genericBatch interface {
	// Queue queues a query to batch b. query can be an SQL query or the name of a
	// prepared statement. See Queue on *pgx.Batch.
	Queue(query string, arguments ...interface{})
}

// NewQuerier creates a DBQuerier that implements Querier. conn is typically
// *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
func NewQuerier(conn genericConn) *DBQuerier {
	return NewQuerierConfig(conn, QuerierConfig{})
}

type QuerierConfig struct {
	// DataTypes contains pgtype.Value to use for encoding and decoding instead
	// of pggen-generated pgtype.ValueTranscoder.
	//
	// If OIDs are available for an input parameter type and all of its
	// transitive dependencies, pggen will use the binary encoding format for
	// the input parameter.
	DataTypes []pgtype.DataType
}

// NewQuerierConfig creates a DBQuerier that implements Querier with the given
// config. conn is typically *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
func NewQuerierConfig(conn genericConn, cfg QuerierConfig) *DBQuerier {
	return &DBQuerier{conn: conn, types: newTypeResolver(cfg.DataTypes)}
}

// WithTx creates a new DBQuerier that uses the transaction to run all queries.
func (q *DBQuerier) WithTx(tx pgx.Tx) (*DBQuerier, error) {
	return &DBQuerier{conn: tx}, nil
}

// preparer is any Postgres connection transport that provides a way to prepare
// a statement, most commonly *pgx.Conn.
type preparer interface {
	Prepare(ctx context.Context, name, sql string) (sd *pgconn.StatementDescription, err error)
}

// PrepareAllQueries executes a PREPARE statement for all pggen generated SQL
// queries in querier files. Typical usage is as the AfterConnect callback
// for pgxpool.Config
//
// pgx will use the prepared statement if available. Calling PrepareAllQueries
// is an optional optimization to avoid a network round-trip the first time pgx
// runs a query if pgx statement caching is enabled.
func PrepareAllQueries(ctx context.Context, p preparer) error {
	if _, err := p.Prepare(ctx, estimateRowCountSQL, estimateRowCountSQL); err != nil {
		return fmt.Errorf("prepare query 'EstimateRowCount': %w", err)
	}
	if _, err := p.Prepare(ctx, getPrimaryKeySQL, getPrimaryKeySQL); err != nil {
		return fmt.Errorf("prepare query 'GetPrimaryKey': %w", err)
	}
	if _, err := p.Prepare(ctx, getColumnTypesSQL, getColumnTypesSQL); err != nil {
		return fmt.Errorf("prepare query 'GetColumnTypes': %w", err)
	}
	if _, err := p.Prepare(ctx, getColumnsSQL, getColumnsSQL); err != nil {
		return fmt.Errorf("prepare query 'GetColumns': %w", err)
	}
	if _, err := p.Prepare(ctx, checkUserPrivilegesSQL, checkUserPrivilegesSQL); err != nil {
		return fmt.Errorf("prepare query 'CheckUserPrivileges': %w", err)
	}
	if _, err := p.Prepare(ctx, spockNodeAndSubInfoSQL, spockNodeAndSubInfoSQL); err != nil {
		return fmt.Errorf("prepare query 'SpockNodeAndSubInfo': %w", err)
	}
	if _, err := p.Prepare(ctx, spockRepSetInfoSQL, spockRepSetInfoSQL); err != nil {
		return fmt.Errorf("prepare query 'SpockRepSetInfo': %w", err)
	}
	return nil
}

// typeResolver looks up the pgtype.ValueTranscoder by Postgres type name.
type typeResolver struct {
	connInfo *pgtype.ConnInfo // types by Postgres type name
}

func newTypeResolver(types []pgtype.DataType) *typeResolver {
	ci := pgtype.NewConnInfo()
	for _, typ := range types {
		if txt, ok := typ.Value.(textPreferrer); ok && typ.OID != unknownOID {
			typ.Value = txt.ValueTranscoder
		}
		ci.RegisterDataType(typ)
	}
	return &typeResolver{connInfo: ci}
}

// findValue find the OID, and pgtype.ValueTranscoder for a Postgres type name.
func (tr *typeResolver) findValue(name string) (uint32, pgtype.ValueTranscoder, bool) {
	typ, ok := tr.connInfo.DataTypeForName(name)
	if !ok {
		return 0, nil, false
	}
	v := pgtype.NewValue(typ.Value)
	return typ.OID, v.(pgtype.ValueTranscoder), true
}

// setValue sets the value of a ValueTranscoder to a value that should always
// work and panics if it fails.
func (tr *typeResolver) setValue(vt pgtype.ValueTranscoder, val interface{}) pgtype.ValueTranscoder {
	if err := vt.Set(val); err != nil {
		panic(fmt.Sprintf("set ValueTranscoder %T to %+v: %s", vt, val, err))
	}
	return vt
}

const estimateRowCountSQL = `SELECT
    (
        CASE
            WHEN s.n_live_tup > 0 THEN s.n_live_tup
            WHEN c.reltuples > 0 THEN c.reltuples
            ELSE pg_relation_size(c.oid) / (8192 * 0.7)
        END
    ) :: bigint AS estimate
FROM
    pg_class c
    JOIN pg_namespace n ON n.oid = c.relnamespace
    LEFT JOIN pg_stat_user_tables s ON s.schemaname = n.nspname
    AND s.relname = c.relname
WHERE
    n.nspname = $1
    AND c.relname = $2;`

// EstimateRowCount implements Querier.EstimateRowCount.
func (q *DBQuerier) EstimateRowCount(ctx context.Context, schemaName pgtype.Name, tableName pgtype.Name) (*int, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "EstimateRowCount")
	row := q.conn.QueryRow(ctx, estimateRowCountSQL, schemaName, tableName)
	var item *int
	if err := row.Scan(&item); err != nil {
		return item, fmt.Errorf("query EstimateRowCount: %w", err)
	}
	return item, nil
}

// EstimateRowCountBatch implements Querier.EstimateRowCountBatch.
func (q *DBQuerier) EstimateRowCountBatch(batch genericBatch, schemaName pgtype.Name, tableName pgtype.Name) {
	batch.Queue(estimateRowCountSQL, schemaName, tableName)
}

// EstimateRowCountScan implements Querier.EstimateRowCountScan.
func (q *DBQuerier) EstimateRowCountScan(results pgx.BatchResults) (*int, error) {
	row := results.QueryRow()
	var item *int
	if err := row.Scan(&item); err != nil {
		return item, fmt.Errorf("scan EstimateRowCountBatch row: %w", err)
	}
	return item, nil
}

const getPrimaryKeySQL = `SELECT
    kcu.column_name
FROM
    information_schema.table_constraints tc
    JOIN information_schema.key_column_usage kcu ON tc.constraint_name = kcu.constraint_name
    AND tc.table_schema = kcu.table_schema
WHERE
    tc.constraint_type = 'PRIMARY KEY'
    AND tc.table_schema = $1
    AND tc.table_name = $2;`

// GetPrimaryKey implements Querier.GetPrimaryKey.
func (q *DBQuerier) GetPrimaryKey(ctx context.Context, schemaName pgtype.Name, tableName pgtype.Name) ([]pgtype.Name, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "GetPrimaryKey")
	rows, err := q.conn.Query(ctx, getPrimaryKeySQL, schemaName, tableName)
	if err != nil {
		return nil, fmt.Errorf("query GetPrimaryKey: %w", err)
	}
	defer rows.Close()
	items := []pgtype.Name{}
	for rows.Next() {
		var item pgtype.Name
		if err := rows.Scan(&item); err != nil {
			return nil, fmt.Errorf("scan GetPrimaryKey row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetPrimaryKey rows: %w", err)
	}
	return items, err
}

// GetPrimaryKeyBatch implements Querier.GetPrimaryKeyBatch.
func (q *DBQuerier) GetPrimaryKeyBatch(batch genericBatch, schemaName pgtype.Name, tableName pgtype.Name) {
	batch.Queue(getPrimaryKeySQL, schemaName, tableName)
}

// GetPrimaryKeyScan implements Querier.GetPrimaryKeyScan.
func (q *DBQuerier) GetPrimaryKeyScan(results pgx.BatchResults) ([]pgtype.Name, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query GetPrimaryKeyBatch: %w", err)
	}
	defer rows.Close()
	items := []pgtype.Name{}
	for rows.Next() {
		var item pgtype.Name
		if err := rows.Scan(&item); err != nil {
			return nil, fmt.Errorf("scan GetPrimaryKeyBatch row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetPrimaryKeyBatch rows: %w", err)
	}
	return items, err
}

const getColumnTypesSQL = `SELECT
    a.attname AS column_name,
    pg_catalog.format_type(a.atttypid, a.atttypmod) AS data_type
FROM
    pg_catalog.pg_attribute a
    JOIN pg_catalog.pg_class c ON a.attrelid = c.oid
    JOIN pg_catalog.pg_type t ON a.atttypid = t.oid
    LEFT JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid
WHERE
    c.relname = $1
    AND a.attnum > 0
    AND NOT a.attisdropped
ORDER BY
    a.attnum;`

type GetColumnTypesRow struct {
	ColumnName pgtype.Name `json:"column_name"`
	DataType   *string     `json:"data_type"`
}

// GetColumnTypes implements Querier.GetColumnTypes.
func (q *DBQuerier) GetColumnTypes(ctx context.Context, tableName pgtype.Name) ([]GetColumnTypesRow, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "GetColumnTypes")
	rows, err := q.conn.Query(ctx, getColumnTypesSQL, tableName)
	if err != nil {
		return nil, fmt.Errorf("query GetColumnTypes: %w", err)
	}
	defer rows.Close()
	items := []GetColumnTypesRow{}
	for rows.Next() {
		var item GetColumnTypesRow
		if err := rows.Scan(&item.ColumnName, &item.DataType); err != nil {
			return nil, fmt.Errorf("scan GetColumnTypes row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetColumnTypes rows: %w", err)
	}
	return items, err
}

// GetColumnTypesBatch implements Querier.GetColumnTypesBatch.
func (q *DBQuerier) GetColumnTypesBatch(batch genericBatch, tableName pgtype.Name) {
	batch.Queue(getColumnTypesSQL, tableName)
}

// GetColumnTypesScan implements Querier.GetColumnTypesScan.
func (q *DBQuerier) GetColumnTypesScan(results pgx.BatchResults) ([]GetColumnTypesRow, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query GetColumnTypesBatch: %w", err)
	}
	defer rows.Close()
	items := []GetColumnTypesRow{}
	for rows.Next() {
		var item GetColumnTypesRow
		if err := rows.Scan(&item.ColumnName, &item.DataType); err != nil {
			return nil, fmt.Errorf("scan GetColumnTypesBatch row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetColumnTypesBatch rows: %w", err)
	}
	return items, err
}

const getColumnsSQL = `SELECT
    column_name
FROM
    information_schema.columns
WHERE
    table_schema = $1
    AND table_name = $2;`

// GetColumns implements Querier.GetColumns.
func (q *DBQuerier) GetColumns(ctx context.Context, schemaName pgtype.Name, tableName pgtype.Name) ([]pgtype.Name, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "GetColumns")
	rows, err := q.conn.Query(ctx, getColumnsSQL, schemaName, tableName)
	if err != nil {
		return nil, fmt.Errorf("query GetColumns: %w", err)
	}
	defer rows.Close()
	items := []pgtype.Name{}
	for rows.Next() {
		var item pgtype.Name
		if err := rows.Scan(&item); err != nil {
			return nil, fmt.Errorf("scan GetColumns row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetColumns rows: %w", err)
	}
	return items, err
}

// GetColumnsBatch implements Querier.GetColumnsBatch.
func (q *DBQuerier) GetColumnsBatch(batch genericBatch, schemaName pgtype.Name, tableName pgtype.Name) {
	batch.Queue(getColumnsSQL, schemaName, tableName)
}

// GetColumnsScan implements Querier.GetColumnsScan.
func (q *DBQuerier) GetColumnsScan(results pgx.BatchResults) ([]pgtype.Name, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query GetColumnsBatch: %w", err)
	}
	defer rows.Close()
	items := []pgtype.Name{}
	for rows.Next() {
		var item pgtype.Name
		if err := rows.Scan(&item); err != nil {
			return nil, fmt.Errorf("scan GetColumnsBatch row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetColumnsBatch rows: %w", err)
	}
	return items, err
}

const checkUserPrivilegesSQL = `WITH params AS (
    SELECT
        $1 :: text AS username,
        $2 :: text AS schema_name,
        $3 :: text AS table_name
),
table_check AS (
    SELECT
        c.relname AS table_name,
        n.nspname AS table_schema
    FROM
        pg_class c
        JOIN pg_namespace n ON n.oid = c.relnamespace
    WHERE
        n.nspname = (
            SELECT
                schema_name
            FROM
                params
        )
        AND c.relname = (
            SELECT
                table_name
            FROM
                params
        )
)
SELECT
    CASE
        WHEN EXISTS (
            SELECT
                1
            FROM
                table_check
        ) THEN has_table_privilege(
            (
                SELECT
                    username
                FROM
                    params
            ),
            (
                SELECT
                    quote_ident(table_schema) || '.' || quote_ident(table_name)
                FROM
                    table_check
            ),
            'SELECT'
        )
        ELSE FALSE
    END AS table_select,
    has_schema_privilege(
        (
            SELECT
                username
            FROM
                params
        ),
        (
            SELECT
                schema_name
            FROM
                params
        ),
        'CREATE'
    ) AS table_create,
    CASE
        WHEN EXISTS (
            SELECT
                1
            FROM
                table_check
        ) THEN has_table_privilege(
            (
                SELECT
                    username
                FROM
                    params
            ),
            (
                SELECT
                    quote_ident(table_schema) || '.' || quote_ident(table_name)
                FROM
                    table_check
            ),
            'INSERT'
        )
        ELSE FALSE
    END AS table_insert,
    CASE
        WHEN EXISTS (
            SELECT
                1
            FROM
                table_check
        ) THEN has_table_privilege(
            (
                SELECT
                    username
                FROM
                    params
            ),
            (
                SELECT
                    quote_ident(table_schema) || '.' || quote_ident(table_name)
                FROM
                    table_check
            ),
            'UPDATE'
        )
        ELSE FALSE
    END AS table_update,
    CASE
        WHEN EXISTS (
            SELECT
                1
            FROM
                table_check
        ) THEN has_table_privilege(
            (
                SELECT
                    username
                FROM
                    params
            ),
            (
                SELECT
                    quote_ident(table_schema) || '.' || quote_ident(table_name)
                FROM
                    table_check
            ),
            'DELETE'
        )
        ELSE FALSE
    END AS table_delete,
    has_table_privilege(
        (
            SELECT
                username
            FROM
                params
        ),
        'information_schema.columns',
        'SELECT'
    ) AS columns_select,
    has_table_privilege(
        (
            SELECT
                username
            FROM
                params
        ),
        'information_schema.table_constraints',
        'SELECT'
    ) AS table_constraints_select,
    has_table_privilege(
        (
            SELECT
                username
            FROM
                params
        ),
        'information_schema.key_column_usage',
        'SELECT'
    ) AS key_column_usage_select;`

type CheckUserPrivilegesParams struct {
	Username    string `json:"username"`
	SchemaName  string `json:"schema_name"`
	TableName   string `json:"table_name"`
}

type CheckUserPrivilegesRow struct {
	TableSelect            *bool `json:"table_select"`
	TableCreate            *bool `json:"table_create"`
	TableInsert            *bool `json:"table_insert"`
	TableUpdate            *bool `json:"table_update"`
	TableDelete            *bool `json:"table_delete"`
	ColumnsSelect          *bool `json:"columns_select"`
	TableConstraintsSelect *bool `json:"table_constraints_select"`
	KeyColumnUsageSelect   *bool `json:"key_column_usage_select"`
}

// CheckUserPrivileges implements Querier.CheckUserPrivileges.
func (q *DBQuerier) CheckUserPrivileges(ctx context.Context, params CheckUserPrivilegesParams) (CheckUserPrivilegesRow, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "CheckUserPrivileges")
	row := q.conn.QueryRow(ctx, checkUserPrivilegesSQL, params.Username, params.SchemaName, params.TableName)
	var item CheckUserPrivilegesRow
	if err := row.Scan(&item.TableSelect, &item.TableCreate, &item.TableInsert, &item.TableUpdate, &item.TableDelete, &item.ColumnsSelect, &item.TableConstraintsSelect, &item.KeyColumnUsageSelect); err != nil {
		return item, fmt.Errorf("query CheckUserPrivileges: %w", err)
	}
	return item, nil
}

// CheckUserPrivilegesBatch implements Querier.CheckUserPrivilegesBatch.
func (q *DBQuerier) CheckUserPrivilegesBatch(batch genericBatch, params CheckUserPrivilegesParams) {
	batch.Queue(checkUserPrivilegesSQL, params.Username, params.SchemaName, params.TableName)
}

// CheckUserPrivilegesScan implements Querier.CheckUserPrivilegesScan.
func (q *DBQuerier) CheckUserPrivilegesScan(results pgx.BatchResults) (CheckUserPrivilegesRow, error) {
	row := results.QueryRow()
	var item CheckUserPrivilegesRow
	if err := row.Scan(&item.TableSelect, &item.TableCreate, &item.TableInsert, &item.TableUpdate, &item.TableDelete, &item.ColumnsSelect, &item.TableConstraintsSelect, &item.KeyColumnUsageSelect); err != nil {
		return item, fmt.Errorf("scan CheckUserPrivilegesBatch row: %w", err)
	}
	return item, nil
}

const spockNodeAndSubInfoSQL = `SELECT
		n.node_id,
		n.node_name,
		n.location,
		n.country,
		s.sub_id,
		s.sub_name,
		s.sub_enabled,
		s.sub_replication_sets
	FROM spock.node n
	LEFT OUTER JOIN spock.subscription s
	ON s.sub_target = n.node_id
	WHERE s.sub_name IS NOT NULL;`

type SpockNodeAndSubInfoRow struct {
	NodeID             pgtype.OID  `json:"node_id"`
	NodeName           pgtype.Name `json:"node_name"`
	Location           *string     `json:"location"`
	Country            *string     `json:"country"`
	SubID              pgtype.OID  `json:"sub_id"`
	SubName            pgtype.Name `json:"sub_name"`
	SubEnabled         *bool       `json:"sub_enabled"`
	SubReplicationSets []string    `json:"sub_replication_sets"`
}

// SpockNodeAndSubInfo implements Querier.SpockNodeAndSubInfo.
func (q *DBQuerier) SpockNodeAndSubInfo(ctx context.Context) ([]SpockNodeAndSubInfoRow, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "SpockNodeAndSubInfo")
	rows, err := q.conn.Query(ctx, spockNodeAndSubInfoSQL)
	if err != nil {
		return nil, fmt.Errorf("query SpockNodeAndSubInfo: %w", err)
	}
	defer rows.Close()
	items := []SpockNodeAndSubInfoRow{}
	for rows.Next() {
		var item SpockNodeAndSubInfoRow
		if err := rows.Scan(&item.NodeID, &item.NodeName, &item.Location, &item.Country, &item.SubID, &item.SubName, &item.SubEnabled, &item.SubReplicationSets); err != nil {
			return nil, fmt.Errorf("scan SpockNodeAndSubInfo row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close SpockNodeAndSubInfo rows: %w", err)
	}
	return items, err
}

// SpockNodeAndSubInfoBatch implements Querier.SpockNodeAndSubInfoBatch.
func (q *DBQuerier) SpockNodeAndSubInfoBatch(batch genericBatch) {
	batch.Queue(spockNodeAndSubInfoSQL)
}

// SpockNodeAndSubInfoScan implements Querier.SpockNodeAndSubInfoScan.
func (q *DBQuerier) SpockNodeAndSubInfoScan(results pgx.BatchResults) ([]SpockNodeAndSubInfoRow, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query SpockNodeAndSubInfoBatch: %w", err)
	}
	defer rows.Close()
	items := []SpockNodeAndSubInfoRow{}
	for rows.Next() {
		var item SpockNodeAndSubInfoRow
		if err := rows.Scan(&item.NodeID, &item.NodeName, &item.Location, &item.Country, &item.SubID, &item.SubName, &item.SubEnabled, &item.SubReplicationSets); err != nil {
			return nil, fmt.Errorf("scan SpockNodeAndSubInfoBatch row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close SpockNodeAndSubInfoBatch rows: %w", err)
	}
	return items, err
}

const spockRepSetInfoSQL = `SELECT
set_name,
array_agg(nspname || '.' || relname ORDER BY nspname, relname) as relname
FROM (
	SELECT
		set_name,
		nspname,
		relname
	FROM spock.tables
	ORDER BY set_name, nspname, relname
) subquery
GROUP BY set_name
ORDER BY set_name;`

type SpockRepSetInfoRow struct {
	SetName pgtype.Name `json:"set_name"`
	Relname []string    `json:"relname"`
}

// SpockRepSetInfo implements Querier.SpockRepSetInfo.
func (q *DBQuerier) SpockRepSetInfo(ctx context.Context) ([]SpockRepSetInfoRow, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "SpockRepSetInfo")
	rows, err := q.conn.Query(ctx, spockRepSetInfoSQL)
	if err != nil {
		return nil, fmt.Errorf("query SpockRepSetInfo: %w", err)
	}
	defer rows.Close()
	items := []SpockRepSetInfoRow{}
	for rows.Next() {
		var item SpockRepSetInfoRow
		if err := rows.Scan(&item.SetName, &item.Relname); err != nil {
			return nil, fmt.Errorf("scan SpockRepSetInfo row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close SpockRepSetInfo rows: %w", err)
	}
	return items, err
}

// SpockRepSetInfoBatch implements Querier.SpockRepSetInfoBatch.
func (q *DBQuerier) SpockRepSetInfoBatch(batch genericBatch) {
	batch.Queue(spockRepSetInfoSQL)
}

// SpockRepSetInfoScan implements Querier.SpockRepSetInfoScan.
func (q *DBQuerier) SpockRepSetInfoScan(results pgx.BatchResults) ([]SpockRepSetInfoRow, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query SpockRepSetInfoBatch: %w", err)
	}
	defer rows.Close()
	items := []SpockRepSetInfoRow{}
	for rows.Next() {
		var item SpockRepSetInfoRow
		if err := rows.Scan(&item.SetName, &item.Relname); err != nil {
			return nil, fmt.Errorf("scan SpockRepSetInfoBatch row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close SpockRepSetInfoBatch rows: %w", err)
	}
	return items, err
}

// textPreferrer wraps a pgtype.ValueTranscoder and sets the preferred encoding
// format to text instead binary (the default). pggen uses the text format
// when the OID is unknownOID because the binary format requires the OID.
// Typically occurs if the results from QueryAllDataTypes aren't passed to
// NewQuerierConfig.
type textPreferrer struct {
	pgtype.ValueTranscoder
	typeName string
}

// PreferredParamFormat implements pgtype.ParamFormatPreferrer.
func (t textPreferrer) PreferredParamFormat() int16 { return pgtype.TextFormatCode }

func (t textPreferrer) NewTypeValue() pgtype.Value {
	return textPreferrer{ValueTranscoder: pgtype.NewValue(t.ValueTranscoder).(pgtype.ValueTranscoder), typeName: t.typeName}
}

func (t textPreferrer) TypeName() string {
	return t.typeName
}

// unknownOID means we don't know the OID for a type. This is okay for decoding
// because pgx call DecodeText or DecodeBinary without requiring the OID. For
// encoding parameters, pggen uses textPreferrer if the OID is unknown.
const unknownOID = 0
