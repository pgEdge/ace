package helpers

import (
	"bytes"
	"context"
	"fmt"
	"regexp"
	"strings"
	"text/template"

	"github.com/jackc/pgx/v4/pgxpool"
)

/*
We have queries.sql.go that's generated by pggen. However, there are some queries
where the identifiers are dynamic, so we cannot parameterise them.

This file contains helper functions for those queries.
*/

var (
	validIdentifierRegex = regexp.MustCompile(`^[A-Za-z_][A-Za-z0-9_]*$`)
)

var pkeyOffsetsTmpl = template.Must(template.New("pkeyOffsets").Parse(`
WITH sampled_data AS (
    SELECT
        {{.KeyColumnsSelect}}
    FROM {{.SchemaIdent}}.{{.TableIdent}}
    TABLESAMPLE {{.TableSampleMethod}}({{.SamplePercent}})
    ORDER BY {{.KeyColumnsOrder}}
),
first_row AS (
    SELECT
        {{.KeyColumnsSelect}}
    FROM {{.SchemaIdent}}.{{.TableIdent}}
    ORDER BY {{.KeyColumnsOrder}}
    LIMIT 1
),
last_row AS (
    SELECT
        {{.KeyColumnsSelect}}
    FROM {{.SchemaIdent}}.{{.TableIdent}}
    ORDER BY {{.KeyColumnsOrderDesc}}
    LIMIT 1
),
sample_boundaries AS (
    SELECT
        {{.KeyColumnsSelect}},
        ntile({{.NtileCount}}) OVER (ORDER BY {{.KeyColumnsOrder}}) as bucket
    FROM sampled_data
),
block_starts AS (
    SELECT DISTINCT ON (bucket)
        {{.KeyColumnsSelect}}
    FROM sample_boundaries
    ORDER BY bucket, {{.KeyColumnsOrder}}
),
all_bounds AS (
    SELECT
        {{.FirstRowSelects}},
        0 as seq
    UNION ALL
    SELECT
        {{.KeyColumnsSelect}},
        1 as seq
    FROM block_starts
    WHERE ({{.KeyColumnsSelect}}) > (
        {{.FirstRowTupleSelects}}
    )
    UNION ALL
    SELECT
        {{.LastRowSelects}},
        2 as seq
),
ranges AS (
    SELECT
        {{.KeyColumnsSelect}},
        {{.RangeStartColumns}},
        {{.RangeEndColumns}},
        seq
    FROM all_bounds
)
SELECT
    {{.RangeOutputColumns}}
FROM ranges
ORDER BY seq;
`))

func SanitiseIdentifier(input string) error {
	if !validIdentifierRegex.MatchString(input) {
		return fmt.Errorf("invalid identifier: %s", input)
	}
	return nil
}

func AvgColumnSize(ctx context.Context, pool *pgxpool.Pool, schema, table, column string) (int64, error) {
	if err := SanitiseIdentifier(schema); err != nil {
		return 0, err
	}
	if err := SanitiseIdentifier(table); err != nil {
		return 0, err
	}
	if err := SanitiseIdentifier(column); err != nil {
		return 0, err
	}

	schemaIdent := fmt.Sprintf("\"%s\"", schema)
	tableIdent := fmt.Sprintf("\"%s\"", table)
	colIdent := fmt.Sprintf("\"%s\"", column)

	query := fmt.Sprintf(
		`SELECT COALESCE(AVG(pg_column_size(%s)), 0) FROM %s.%s`,
		colIdent, schemaIdent, tableIdent,
	)

	var avgSize int64
	if err := pool.QueryRow(ctx, query).Scan(&avgSize); err != nil {
		return 0, fmt.Errorf("AvgColumnSize query failed for %s.%s.%s: %w", schema, table, column, err)
	}

	return avgSize, nil
}

func BlockHash(ctx context.Context, pool *pgxpool.Pool, schema, table string, cols []string, primaryKey string, start interface{}, end interface{}) (string, error) {
	if err := SanitiseIdentifier(schema); err != nil {
		return "", err
	}
	if err := SanitiseIdentifier(table); err != nil {
		return "", err
	}
	if err := SanitiseIdentifier(primaryKey); err != nil {
		return "", err
	}
	for _, col := range cols {
		if err := SanitiseIdentifier(col); err != nil {
			return "", err
		}
	}
	schemaIdent := fmt.Sprintf("\"%s\"", schema)
	tableIdent := fmt.Sprintf("\"%s\"", table)
	primaryIdent := fmt.Sprintf("\"%s\"", primaryKey)
	var colIdents []string
	for _, col := range cols {
		colIdents = append(colIdents, fmt.Sprintf("\"%s\"", col))
	}
	colsList := strings.Join(colIdents, ", ")
	query := fmt.Sprintf(
		`SELECT encode(digest(COALESCE(string_agg(concat_ws('|', %s),'|' ORDER BY %s),'EMPTY_BLOCK'),'sha256'),'hex') FROM %s.%s WHERE %s >= $1 AND %s < $2`,
		colsList, primaryIdent, schemaIdent, tableIdent, primaryIdent, primaryIdent,
	)
	var hash string
	if err := pool.QueryRow(ctx, query, start, end).Scan(&hash); err != nil {
		return "", fmt.Errorf("BlockHash query failed for %s.%s range %v-%v: %w", schema, table, start, end, err)
	}
	return hash, nil
}

func GeneratePkeyOffsetsQuery(
	schema, table string,
	keyColumns []string,
	tableSampleMethod string,
	samplePercent float64,
	ntileCount int,
) (string, error) {
	for _, ident := range append(keyColumns, schema, table) {
		if err := SanitiseIdentifier(ident); err != nil {
			return "", fmt.Errorf("invalid identifier %q: %w", ident, err)
		}
	}
	schemaIdent := fmt.Sprintf(`"%s"`, schema)
	tableIdent := fmt.Sprintf(`"%s"`, table)

	keyColsSelect := strings.Join(keyColumns, ",\n        ")
	keyColsOrder := strings.Join(keyColumns, ", ")

	var descs []string
	for _, c := range keyColumns {
		descs = append(descs, fmt.Sprintf("%s DESC", c))
	}
	keyColsOrderDesc := strings.Join(descs, ", ")

	var firstSelects, lastSelects, firstTuples []string
	for _, c := range keyColumns {
		firstSelects = append(firstSelects,
			fmt.Sprintf("(SELECT %s FROM first_row) AS %s", c, c))
		lastSelects = append(lastSelects,
			fmt.Sprintf("(SELECT %s FROM last_row) AS %s", c, c))
		firstTuples = append(firstTuples,
			fmt.Sprintf("(SELECT %s FROM first_row)", c))
	}

	var rangeStarts, rangeEnds, rangeOutputs []string
	for _, c := range keyColumns {
		rangeStarts = append(rangeStarts, fmt.Sprintf("%s AS range_start_%s", c, c))
		rangeEnds = append(rangeEnds, fmt.Sprintf(
			"LEAD(%s) OVER (ORDER BY seq, %s) AS range_end_%s",
			c, keyColsOrder, c,
		))
		rangeOutputs = append(rangeOutputs,
			fmt.Sprintf("range_start_%s,\n    range_end_%s", c, c))
	}

	data := map[string]any{
		"SchemaIdent":          schemaIdent,
		"TableIdent":           tableIdent,
		"TableSampleMethod":    tableSampleMethod,
		"SamplePercent":        samplePercent,
		"NtileCount":           ntileCount,
		"KeyColumnsSelect":     keyColsSelect,
		"KeyColumnsOrder":      keyColsOrder,
		"KeyColumnsOrderDesc":  keyColsOrderDesc,
		"FirstRowSelects":      strings.Join(firstSelects, ",\n        "),
		"LastRowSelects":       strings.Join(lastSelects, ",\n        "),
		"FirstRowTupleSelects": strings.Join(firstTuples, ",\n        "),
		"RangeStartColumns":    strings.Join(rangeStarts, ",\n        "),
		"RangeEndColumns":      strings.Join(rangeEnds, ",\n        "),
		"RangeOutputColumns":   strings.Join(rangeOutputs, ",\n    "),
	}

	var buf bytes.Buffer
	if err := pkeyOffsetsTmpl.Execute(&buf, data); err != nil {
		return "", fmt.Errorf("failed to render pkey offsets SQL: %w", err)
	}
	return buf.String(), nil
}

// BlockHashSQL returns the SQL string for hashing a block of rows using the given schema, table, columns, and primary key.
func BlockHashSQL(schema, table string, cols []string, primaryKey string) (string, error) {
	if err := SanitiseIdentifier(schema); err != nil {
		return "", err
	}
	if err := SanitiseIdentifier(table); err != nil {
		return "", err
	}
	if err := SanitiseIdentifier(primaryKey); err != nil {
		return "", err
	}
	for _, col := range cols {
		if err := SanitiseIdentifier(col); err != nil {
			return "", err
		}
	}
	schemaIdent := fmt.Sprintf("\"%s\"", schema)
	tableIdent := fmt.Sprintf("\"%s\"", table)
	primaryIdent := fmt.Sprintf("\"%s\"", primaryKey)
	var colIdents []string
	for _, col := range cols {
		colIdents = append(colIdents, fmt.Sprintf("\"%s\"", col))
	}
	colsList := strings.Join(colIdents, ", ")
	query := fmt.Sprintf(
		`SELECT encode(digest(COALESCE(string_agg(concat_ws('|', %s),'|' ORDER BY %s),'EMPTY_BLOCK'),'sha256'),'hex') FROM %s.%s WHERE %s >= $1 AND %s < $2`,
		colsList, primaryIdent, schemaIdent, tableIdent, primaryIdent, primaryIdent,
	)
	return query, nil
}
