package helpers

import (
	"bytes"
	"context"
	"fmt"
	"regexp"
	"strings"
	"text/template"

	"github.com/jackc/pgx/v4"
)

/*
We have queries.sql.go that's generated by pggen. However, there are some queries
where the identifiers are dynamic, so we cannot parameterise them.

This file contains helper functions for those queries.
*/

var (
	validIdentifierRegex = regexp.MustCompile(`^[A-Za-z_][A-Za-z0-9_]*$`)
)

var pkeyOffsetsTmpl = template.Must(template.New("pkeyOffsets").Parse(`
WITH sampled_data AS (
    SELECT
        {{.KeyColumnsSelect}}
    FROM {{.SchemaIdent}}.{{.TableIdent}}
    TABLESAMPLE {{.TableSampleMethod}}({{.SamplePercent}})
    ORDER BY {{.KeyColumnsOrder}}
),
first_row AS (
    SELECT
        {{.KeyColumnsSelect}}
    FROM {{.SchemaIdent}}.{{.TableIdent}}
    ORDER BY {{.KeyColumnsOrder}}
    LIMIT 1
),
last_row AS (
    SELECT
        {{.KeyColumnsSelect}}
    FROM {{.SchemaIdent}}.{{.TableIdent}}
    ORDER BY {{.KeyColumnsOrderDesc}}
    LIMIT 1
),
sample_boundaries AS (
    SELECT
        {{.KeyColumnsSelect}},
        ntile({{.NtileCount}}) OVER (ORDER BY {{.KeyColumnsOrder}}) as bucket
    FROM sampled_data
),
block_starts AS (
    SELECT DISTINCT ON (bucket)
        {{.KeyColumnsSelect}}
    FROM sample_boundaries
    ORDER BY bucket, {{.KeyColumnsOrder}}
),
all_bounds AS (
    SELECT
        {{.FirstRowSelects}},
        0 as seq
    UNION ALL
    SELECT
        {{.KeyColumnsSelect}},
        1 as seq
    FROM block_starts
    WHERE ({{.KeyColumnsSelect}}) > (
        {{.FirstRowTupleSelects}}
    )
    UNION ALL
    SELECT
        {{.LastRowSelects}},
        2 as seq
),
ranges AS (
    SELECT
        {{.KeyColumnsSelect}},
        {{.RangeStartColumns}},
        {{.RangeEndColumns}},
        seq
    FROM all_bounds
)
SELECT
    {{.RangeOutputColumns}}
FROM ranges
ORDER BY seq;
`))

// For mocking
type DBQuerier interface {
	QueryRow(ctx context.Context, sql string, args ...any) pgx.Row
}

func SanitiseIdentifier(input string) error {
	if !validIdentifierRegex.MatchString(input) {
		return fmt.Errorf("invalid identifier: %s", input)
	}
	return nil
}

func MaxColumnSize(ctx context.Context, db DBQuerier, schema, table, column string) (int64, error) {
	if err := SanitiseIdentifier(schema); err != nil {
		return 0, err
	}
	if err := SanitiseIdentifier(table); err != nil {
		return 0, err
	}
	if err := SanitiseIdentifier(column); err != nil {
		return 0, err
	}

	schemaIdent := fmt.Sprintf(`"%s"`, schema)
	tableIdent := fmt.Sprintf(`"%s"`, table)
	colIdent := fmt.Sprintf(`"%s"`, column)

	query := fmt.Sprintf(
		`SELECT COALESCE(MAX(octet_length(%s))::bigint, 0) FROM %s.%s`,
		colIdent, schemaIdent, tableIdent,
	)

	var maxSize int64
	if err := db.QueryRow(ctx, query).Scan(&maxSize); err != nil {
		return 0, fmt.Errorf(
			"MaxColumnSize query failed for %s.%s.%s: %w",
			schema,
			table,
			column,
			err,
		)
	}

	return maxSize, nil
}

func GeneratePkeyOffsetsQuery(
	schema, table string,
	keyColumns []string,
	tableSampleMethod string,
	samplePercent float64,
	ntileCount int,
) (string, error) {
	if len(keyColumns) == 0 {
		return "", fmt.Errorf("keyColumns cannot be empty")
	}
	for _, ident := range append([]string{schema, table}, keyColumns...) {
		if err := SanitiseIdentifier(ident); err != nil {
			return "", fmt.Errorf("invalid identifier %q: %w", ident, err)
		}
	}
	schemaIdent := fmt.Sprintf(`"%s"`, schema)
	tableIdent := fmt.Sprintf(`"%s"`, table)

	quotedKeyColsOriginal := make([]string, len(keyColumns))
	for i, c := range keyColumns {
		quotedKeyColsOriginal[i] = fmt.Sprintf(`"%s"`, c)
	}

	keyColsSelect := strings.Join(quotedKeyColsOriginal, ",\n        ")
	keyColsOrder := strings.Join(quotedKeyColsOriginal, ", ")

	var descs []string
	for _, c := range keyColumns {
		descs = append(descs, fmt.Sprintf(`"%s" DESC`, c))
	}
	keyColsOrderDesc := strings.Join(descs, ", ")

	var firstSelects, lastSelects, firstTuples []string
	for _, c := range keyColumns {
		quotedCol := fmt.Sprintf(`"%s"`, c)
		firstSelects = append(firstSelects,
			fmt.Sprintf(`(SELECT %s FROM first_row) AS %s`, quotedCol, quotedCol))
		lastSelects = append(lastSelects,
			fmt.Sprintf(`(SELECT %s FROM last_row) AS %s`, quotedCol, quotedCol))
		firstTuples = append(firstTuples,
			fmt.Sprintf(`(SELECT %s FROM first_row)`, quotedCol))
	}

	var rangeStarts, rangeEnds []string
	for _, c := range keyColumns {
		quotedCol := fmt.Sprintf(`"%s"`, c)
		aliasStart := fmt.Sprintf(`range_start_%s`, c)
		quotedAliasStart := fmt.Sprintf(`"%s"`, aliasStart)

		aliasEnd := fmt.Sprintf(`range_end_%s`, c)
		quotedAliasEnd := fmt.Sprintf(`"%s"`, aliasEnd)

		rangeStarts = append(rangeStarts, fmt.Sprintf(`%s AS %s`, quotedCol, quotedAliasStart))
		rangeEnds = append(rangeEnds, fmt.Sprintf(
			`LEAD(%s) OVER (ORDER BY seq, %s) AS %s`,
			quotedCol, keyColsOrder, quotedAliasEnd,
		))
	}

	var startComponentCols []string
	var endComponentCols []string
	for _, c := range keyColumns {
		aliasStart := fmt.Sprintf(`range_start_%s`, c)
		quotedAliasStart := fmt.Sprintf(`"%s"`, aliasStart)
		startComponentCols = append(startComponentCols, quotedAliasStart)

		aliasEnd := fmt.Sprintf(`range_end_%s`, c)
		quotedAliasEnd := fmt.Sprintf(`"%s"`, aliasEnd)
		endComponentCols = append(endComponentCols, quotedAliasEnd)
	}
	selectOutputCols := append(startComponentCols, endComponentCols...)

	data := map[string]any{
		"SchemaIdent":          schemaIdent,
		"TableIdent":           tableIdent,
		"TableSampleMethod":    tableSampleMethod,
		"SamplePercent":        samplePercent,
		"NtileCount":           ntileCount,
		"KeyColumnsSelect":     keyColsSelect,
		"KeyColumnsOrder":      keyColsOrder,
		"KeyColumnsOrderDesc":  keyColsOrderDesc,
		"FirstRowSelects":      strings.Join(firstSelects, ",\n        "),
		"LastRowSelects":       strings.Join(lastSelects, ",\n        "),
		"FirstRowTupleSelects": strings.Join(firstTuples, ",\n        "),
		"RangeStartColumns":    strings.Join(rangeStarts, ",\n        "),
		"RangeEndColumns":      strings.Join(rangeEnds, ",\n        "),
		"RangeOutputColumns":   strings.Join(selectOutputCols, ",\n    "),
	}

	var buf bytes.Buffer
	if err := pkeyOffsetsTmpl.Execute(&buf, data); err != nil {
		return "", fmt.Errorf("failed to render pkey offsets SQL: %w", err)
	}
	return buf.String(), nil
}

func BlockHashSQL(schema, table string, primaryKeyCols []string) (string, error) {
	if len(primaryKeyCols) == 0 {
		return "", fmt.Errorf("primaryKeyCols cannot be empty")
	}
	if err := SanitiseIdentifier(schema); err != nil {
		return "", err
	}
	if err := SanitiseIdentifier(table); err != nil {
		return "", err
	}

	for _, pkCol := range primaryKeyCols {
		if pkCol == "" {
			return "", fmt.Errorf("primary key column identifier cannot be empty")
		}
		if err := SanitiseIdentifier(pkCol); err != nil {
			return "", fmt.Errorf("invalid primary key column identifier %q: %w", pkCol, err)
		}
	}

	schemaIdent := fmt.Sprintf(`"%s"`, schema)
	tableIdent := fmt.Sprintf(`"%s"`, table)
	tableAlias := "_tbl_"

	quotedPKColIdents := make([]string, len(primaryKeyCols))
	for i, pkCol := range primaryKeyCols {
		quotedPKColIdents[i] = fmt.Sprintf(`"%s"`, pkCol)
	}
	pkOrderByStr := strings.Join(quotedPKColIdents, ", ")

	pkComparisonExpression := ""
	if len(primaryKeyCols) == 1 {
		pkComparisonExpression = quotedPKColIdents[0]
	} else {
		pkComparisonExpression = fmt.Sprintf("ROW(%s)", strings.Join(quotedPKColIdents, ", "))
	}

	startPlaceholders := make([]string, len(primaryKeyCols))
	for i := range primaryKeyCols {
		startPlaceholders[i] = fmt.Sprintf("$%d", 2+i)
	}
	startValueExpression := ""
	if len(primaryKeyCols) == 1 {
		startValueExpression = startPlaceholders[0]
	} else {
		startValueExpression = fmt.Sprintf("ROW(%s)", strings.Join(startPlaceholders, ", "))
	}

	skipMaxCheckPlaceholderIndex := 2 + len(primaryKeyCols)

	endPlaceholders := make([]string, len(primaryKeyCols))
	for i := range primaryKeyCols {
		endPlaceholders[i] = fmt.Sprintf("$%d", skipMaxCheckPlaceholderIndex+1+i)
	}
	endValueExpression := ""
	if len(primaryKeyCols) == 1 {
		endValueExpression = endPlaceholders[0]
	} else {
		endValueExpression = fmt.Sprintf("ROW(%s)", strings.Join(endPlaceholders, ", "))
	}

	query := fmt.Sprintf(
		`SELECT encode(digest(COALESCE(string_agg(%s::text, '|' ORDER BY %s), '[EMPTY_BLOCK]'), 'sha1'), 'hex')
		 FROM %s.%s AS %s
		 WHERE ($1::boolean OR %s >= %s)
		   AND ($%d::boolean OR %s < %s)`,
		tableAlias,
		pkOrderByStr,
		schemaIdent,
		tableIdent,
		tableAlias,
		pkComparisonExpression,
		startValueExpression,
		skipMaxCheckPlaceholderIndex,
		pkComparisonExpression,
		endValueExpression,
	)
	return query, nil
}
